import duckdb
import pandas as pd
from packaging import version
from datetime import datetime, timedelta
import time # Import time module for timing
from typing import List, Dict, Union
import configparser

# å®šä¹‰æ—¶é—´çª—å£å’Œå›è¸©æ¡ä»¶
HISTORY_DAYS = 40  # æ”¯æ’‘ä»·å‘å‰çœ‹çš„å¤©æ•°
FUTURE_DAYS = 40   # å›è¸©æ—¥å‘åçœ‹çš„å¤©æ•°
VOLATILITY_LIMIT = 0.05  # å›è¸©æ—¥æ³¢åŠ¨æ€§é™åˆ¶ï¼ˆCæ¡ä»¶ï¼‰
SUPPORT_PRICE_TOLERANCE = 0.995 # å›è¸©æ—¥æœ€ä½ä»·è¦åŒ…å«æ”¯æŒä»·çš„æ¯”ä¾‹ï¼ˆAæ¡ä»¶ï¼‰

# åŠ è½½éœ€è¦åšå›æµ‹è¿ç®—çš„xlsxæ–‡ä»¶
def load_df_from_excel_file(file_path):
    df = None
    try:
        # è¯»å– Excel æ–‡ä»¶çš„ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨ï¼Œç¬¬ä¸€è¡Œä½œä¸ºåˆ—å
        df = pd.read_excel(file_path, sheet_name=0, engine='openpyxl', header=0)
    except FileNotFoundError:
        print(f"Error: File '{file_path}' not found")
    except Exception as e:
        print(f"Error: {str(e)}")
    return df

# æŠŠdfä¸­æŸåˆ—çš„å€¼è½¬æ¢ä¸ºdatetimeæ ¼å¼
def convert_date_format_of_df_column(df, column_name="å¤‡æ³¨"):
    try:
        # å°†â€œå¤‡æ³¨â€åˆ—ä» yyyyMMdd è½¬æ¢ä¸º yyyy-MM-dd
        df[column_name] = pd.to_datetime(df[column_name], format='%Y%m%d').dt.strftime('%Y-%m-%d')
        return df
    except Exception as e:
        print(f"Error converting dates in column '{column_name}': {str(e)}")
        return df

def load_target_df(excel_file_path: str):
    df = load_df_from_excel_file(excel_file_path)
    convert_date_format_of_df_column(df=df)

    # å¤åˆ¶å¤‡æ³¨åˆ—ä¸ºbreakthrough_date
    df['breakthrough_date'] = df['å¤‡æ³¨']
    df['stock_code'] = df['ä»£ç '].str.lower()
    stock_data_list = (
        df.rename(columns={
            'å¤‡æ³¨': 'breakthrough_date',
            'ä»£ç ': 'stock_code',
            '    åç§°': 'stock_name',
            'ç°ä»·': 'adj_stock_price'}
        )[['breakthrough_date', 'stock_code', 'stock_name', 'adj_stock_price']].to_dict(orient='records')
    )
    stock_data_df = pd.DataFrame(stock_data_list)
    return stock_data_df

# ä»åº“ä¸­æ‰¾å‡ºå¤æƒè®¡ç®—è¿‡çš„æ•°æ®ã€‚
def get_next_N_days_data(stock_data_list, max_holding_days):
    """
    Connects to DuckDB, creates/ensures stock_data table exists (for testing),
    and queries stocks satisfying specific conditions using DuckDB.
    """

    # åˆ›å»º ConfigParser å¯¹è±¡
    config = configparser.ConfigParser()

    # è¯»å– .conf æ–‡ä»¶
    config.read('./config.conf')
    earliest_time_limit=config['settings']['earliest_time_limit']                                   # äº¤æ˜“æ—¥æœŸçš„æœ€æ—©æ—¶é™ï¼Œè¯¥æ—¥å‰çš„äº¤æ˜“æ•°æ®ï¼Œä¸ä¼šè¢«çº³å…¥é€‰æ‹©
    cond1_and_cond3=config['settings']['cond1_and_cond3']                                           # æ¡ä»¶1å’Œæ¡ä»¶3çš„é…ç½®é¡¹ã€‚
    cond2=config['settings']['cond2']                                                               # æ¡ä»¶2ï¼šå‰Nä¸ªäº¤æ˜“æ—¥å†…æœ‰æ¶¨å¹…ï¼ˆå¤§äºç­‰äº5%ï¼‰çš„Kçº¿
    apply_cond2_or_not=config['settings']['apply_cond2_or_not']                                     # æ˜¯å¦å¯ç”¨æ¡ä»¶2ï¼šyes, å¯ç”¨; no: ä¸å¯ç”¨ã€‚
    apply_cond5_or_not=config['settings']['apply_cond5_or_not']                                     # æ˜¯å¦å¯ç”¨æ¡ä»¶5ï¼šyes, å¯ç”¨; no: ä¸å¯ç”¨ã€‚
    # history_trading_days=config['settings']['history_trading_days']                               # æ¡ä»¶1ï¼šå†å²äº¤æ˜“æ—¥é€‰æ‹©èŒƒå›´ã€‚40: 40ä¸ªäº¤æ˜“æ—¥ï¼Œ60: 60ä¸ªäº¤æ˜“æ—¥ï¼Œ80: 80ä¸ªäº¤æ˜“æ—¥
    # main_board_amplitude_threshold=config['settings']['main_board_amplitude_threshold']           # æ¡ä»¶3ï¼šä¸»æ¿æŒ¯å¹…ã€‚25: 25%, 30: 30%, 35: 35%
    # non_main_board_amplitude_threshold=config['settings']['non_main_board_amplitude_threshold']   # æ¡ä»¶3ï¼šåˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿ä¸»æ¿æŒ¯å¹…ã€‚35: 35%ï¼Œ 40: 40%ã€‚
    history_trading_days=cond1_and_cond3.split('_')[0]
    main_board_amplitude_threshold=cond1_and_cond3.split('_')[1]
    non_main_board_amplitude_threshold=cond1_and_cond3.split('_')[2]
    max_market_capitalization=config['settings']['max_market_capitalization']                       # æœ€å¤§æµé€šå¸‚å€¼ï¼Œå•ä½äº¿ã€‚
    min_market_capitalization=config['settings']['min_market_capitalization']                       # æœ€å°æµé€šå¸‚å€¼ï¼Œå•ä½äº¿ã€‚
    net_profit_growth_rate=config['settings']['net_profit_growth_rate']                             # å‡€åˆ©æ¶¦å¢é•¿ç‡ã€‚-20: -20%ã€‚
    total_revenue_growth_rate=config['settings']['total_revenue_growth_rate']                       # è¥ä¸šæ€»æ”¶å…¥å¢é•¿ç‡ã€‚-20: -20%ã€‚
    use_cond_1_1_or_cond_1_2=config['settings']['use_cond_1_1_or_cond_1_2']                         # ä½¿ç”¨æ¡ä»¶1.1è¿˜æ˜¯1.2è¿›è¡Œç­›é€‰ï¼š1.1ï¼Œä½¿ç”¨æ¡ä»¶1.1; 1.2, ä½¿ç”¨æ¡ä»¶1.2ã€‚
    range_days_of_cond_1_2=config['settings']['range_days_of_cond_1_2']                             # ä½¿ç”¨æ¡ä»¶1.2æ—¶ï¼Œå…¶åNä¸ªäº¤æ˜“æ—¥è®¾å®šå€¼

    cond2_sql_where_clause = ''
    if apply_cond2_or_not == 'yes':
        cond2_sql_where_clause = 'AND has_gain_5_percent = 1'
    if apply_cond2_or_not == 'no':
        cond2_sql_where_clause = '-- AND has_gain_5_percent = 1'

    cond5_sql_where_clause = ''
    if apply_cond5_or_not == 'yes':
        cond5_sql_where_clause = f'AND net_profit_yoy >= {net_profit_growth_rate} AND revenue_yoy >= {total_revenue_growth_rate}'
    if apply_cond5_or_not == 'no':
        cond5_sql_where_clause = f''

    # Connect to DuckDB database file
    # Ensure 'stock_data.duckdb' exists and contains data,
    # or uncomment the data generation part below for testing.
    con = duckdb.connect(database='stock_data.duckdb', read_only=False)
    print("è¿æ¥åˆ°æ•°æ®åº“: stock_data.duckdb")
    
    stock_code_list = ", ".join(f"'{item['stock_code']}'" for item in stock_data_list)
    days_limit = 41 if max_holding_days is None else (int(max_holding_days) + 1)

    # Main Query SQL (optimized for DuckDB)
    # The SQL is mostly the same as DuckDB handles window functions efficiently.
    query_sql = f"""
    -- ğŸ“ è®¡ç®—ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨äº¤æ˜“æ—¥çª—å£
    WITH DeduplicatedStockData AS (
        -- âœ… å»æ‰ stock_data ä¸­å®Œå…¨é‡å¤çš„è¡Œ
        SELECT DISTINCT stock_code, stock_name, trade_date, open_price, close_price, high_price, low_price, prev_close_price, market_cap, total_market_cap, industry_level1, industry_level2, industry_level3 
        FROM stock_data
        -- ğŸ”§ é™å®š stock_code èŒƒå›´ï¼ŒåªæŸ¥è¯¢ç»™å®šè‚¡ç¥¨åˆ—è¡¨
        WHERE stock_code IN (
            -- âš ï¸ è¿™é‡Œçš„ stock_code_list å¯ä»¥æ˜¯ Python æ ¼å¼ ['AAPL','TSM'] è½¬æ¢æˆ SQL å­—ç¬¦ä¸² 'AAPL','TSM'
            {stock_code_list}
        )
    ),
    StockWithRiseFall AS (
        -- âœ… è®¡ç®—å¤æƒæ¶¨è·Œå¹…ï¼Œå…¬å¼: å¤æƒæ¶¨è·Œå¹… = æ”¶ç›˜ä»· / å‰æ”¶ç›˜ä»· - 1
        SELECT *,
            (close_price / NULLIF(prev_close_price, 0)) - 1 AS rise_fall
        FROM DeduplicatedStockData
    ),
    AdjustmentFactorComputed AS (
        -- âœ… è®¡ç®—å¤æƒå› å­, å…¬å¼: å¤æƒå› å­ = (1 + å¤æƒæ¶¨è·Œå¹…).cumprod()
        SELECT *,
            EXP(SUM(LN(1 + rise_fall)) OVER (PARTITION BY stock_code ORDER BY trade_date)) AS adjustment_factor
        FROM StockWithRiseFall
    ),
    LastRecordComputed AS (
        -- âœ… è·å–æ¯ä¸ª stock_code çš„æœ€åä¸€æ¡è®°å½•çš„æ”¶ç›˜ä»·å’Œå¤æƒå› å­
        SELECT 
            t.stock_code,
            t.close_price AS last_close_price,
            t.adjustment_factor AS last_adjustment_factor
        FROM (
            SELECT 
                stock_code,
                close_price,
                adjustment_factor,
                ROW_NUMBER() OVER (PARTITION BY stock_code ORDER BY trade_date DESC) AS rn
            FROM AdjustmentFactorComputed
        ) t
        WHERE t.rn = 1
    ),
    AdjustedStockData AS (
        SELECT 
            a.*,
            -- âœ… è®¡ç®—å‰å¤æƒæ”¶ç›˜ä»·, å…¬å¼: å‰å¤æƒæ”¶ç›˜ä»· = å¤æƒå› å­ * (æœ€åä¸€æ¡æ•°æ®çš„æ”¶ç›˜ä»· / æœ€åä¸€æ¡æ•°æ®çš„å¤æƒå› å­)
            a.adjustment_factor * (l.last_close_price / NULLIF(l.last_adjustment_factor, 0)) AS adj_close_price,
            -- âœ… å‰å¤æƒå…¶ä»–ä»·æ ¼
            (a.open_price / NULLIF(a.close_price, 0)) * (a.adjustment_factor * (l.last_close_price / NULLIF(l.last_adjustment_factor, 0))) AS adj_open_price,
            (a.high_price / NULLIF(a.close_price, 0)) * (a.adjustment_factor * (l.last_close_price / NULLIF(l.last_adjustment_factor, 0))) AS adj_high_price,
            (a.low_price / NULLIF(a.close_price, 0)) * (a.adjustment_factor * (l.last_close_price / NULLIF(l.last_adjustment_factor, 0))) AS adj_low_price,
            (a.prev_close_price / NULLIF(a.close_price, 0)) * (a.adjustment_factor * (l.last_close_price / NULLIF(l.last_adjustment_factor, 0))) AS adj_prev_close_price
        FROM AdjustmentFactorComputed a
        LEFT JOIN LastRecordComputed l ON a.stock_code = l.stock_code
    ),
    StockWindows AS (
        SELECT
            t.stock_code,
            t.trade_date,
            t.stock_name,
            t.close_price,
            t.high_price,
            t.low_price,
            t.open_price,
            t.adj_close_price,
            t.adj_high_price,
            t.adj_low_price,
            t.adj_open_price,
            t.industry_level1,
            t.industry_level2,
            t.industry_level3,
            -- âœ… æµé€šå¸‚å€¼æ¢ç®—æˆâ€œäº¿â€
            (t.market_cap / 100000000) AS market_cap_of_100_million,
            -- 
            (t.total_market_cap / 100000000) AS total_market_cap_of_100_million,
            -- âœ… Nä¸ªäº¤æ˜“æ—¥å†…ï¼ˆä¸å«å½“æ—¥ï¼‰çš„æœ€é«˜æ”¶ç›˜ä»·, ä½¿ç”¨çš„æ˜¯å¤æƒåçš„æ”¶ç›˜ä»·
            MAX(t.adj_close_price) OVER (
                PARTITION BY t.stock_code
                ORDER BY t.trade_date
                ROWS BETWEEN {history_trading_days} PRECEDING AND 1 PRECEDING
            ) AS max_close_n_days,
            -- âœ… å¯¹åº”çš„æœ€é«˜æ”¶ç›˜ä»·æ—¥æœŸ
            arg_max(t.trade_date, t.adj_close_price) OVER (
                PARTITION BY t.stock_code
                ORDER BY t.trade_date
                ROWS BETWEEN {history_trading_days} PRECEDING AND 1 PRECEDING
            ) AS max_close_n_days_date,
            -- âœ… Nä¸ªäº¤æ˜“æ—¥çª—å£å†…ï¼ˆä¸å«å½“æ—¥ï¼‰çš„æœ€é«˜ä»·ï¼ˆç”¨äºæŒ¯å¹…è®¡ç®—ï¼‰, ä½¿ç”¨çš„æ˜¯å¤æƒåçš„æœ€é«˜ä»·
            MAX(t.adj_high_price) OVER (
                PARTITION BY t.stock_code
                ORDER BY t.trade_date
                ROWS BETWEEN {history_trading_days} PRECEDING AND 1 PRECEDING
            ) AS max_high_n_days,
            -- âœ… Nä¸ªäº¤æ˜“æ—¥çª—å£å†…ï¼ˆä¸å«å½“æ—¥ï¼‰çš„æœ€ä½ä»·ï¼ˆç”¨äºæŒ¯å¹…è®¡ç®—ï¼‰, ä½¿ç”¨çš„æ˜¯å¤æƒåçš„æœ€ä½ä»·
            MIN(t.adj_low_price) OVER (
                PARTITION BY t.stock_code
                ORDER BY t.trade_date
                ROWS BETWEEN {history_trading_days} PRECEDING AND 1 PRECEDING
            ) AS min_low_n_days,
            -- âœ… Nä¸ªäº¤æ˜“æ—¥å†…ï¼ˆä¸å«å½“æ—¥ï¼‰çš„ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜ä»·ï¼Œç”¨ä½œæŒ¯å¹…åˆ†æ¯ã€‚ä½¿ç”¨çš„æ˜¯å¤æƒåçš„å¼€ç›˜ä»·ã€‚
            FIRST_VALUE(t.adj_open_price) OVER (
                PARTITION BY t.stock_code
                ORDER BY t.trade_date
                ROWS BETWEEN {history_trading_days} PRECEDING AND 1 PRECEDING
            ) AS open_price_of_first_day_of_n_days,
            -- âœ… Nä¸ªäº¤æ˜“æ—¥å†…æ˜¯å¦å­˜åœ¨å•æ—¥æ¶¨å¹… â‰¥ 5%
            MAX(CASE
                WHEN (t.adj_close_price - t.adj_prev_close_price) / NULLIF(t.adj_prev_close_price, 0) >= {cond2} THEN 1
                ELSE 0
            END) OVER (
                PARTITION BY t.stock_code
                ORDER BY t.trade_date
                ROWS BETWEEN {history_trading_days} PRECEDING AND 1 PRECEDING
            ) AS has_gain_5_percent,
            -- âœ… è¡Œå·ï¼šç¡®ä¿çª—å£è‡³å°‘åŒ…å«Nä¸ªäº¤æ˜“æ—¥
            ROW_NUMBER() OVER (
                PARTITION BY t.stock_code
                ORDER BY t.trade_date
            ) AS rn
        FROM
            AdjustedStockData t
        WHERE
            -- âœ… æ’é™¤åŒ—äº¤æ‰€è‚¡ç¥¨
            t.stock_code NOT LIKE 'bj%' AND
            -- âœ… æ’é™¤2022å¹´1æœˆ1å·ä¹‹å‰çš„äº¤æ˜“æ•°æ®
            t.trade_date >= '{earliest_time_limit}'
    ),
    FilteredStockData AS (
        SELECT
            sw.stock_code,
            sw.stock_name,
            sw.trade_date,
            sw.adj_close_price,
            sw.adj_high_price,
            sw.adj_low_price,
            sw.adj_open_price,
            sw.max_close_n_days,
            sw.max_close_n_days_date,
            sw.market_cap_of_100_million,
            sw.total_market_cap_of_100_million,
            sw.industry_level1,
            sw.industry_level2,
            sw.industry_level3
        FROM
            StockWindows AS sw
        WHERE
            -- ğŸ“Œ æ¡ä»¶0ï¼šçª—å£å†…è‡³å°‘æœ‰Nä¸ªäº¤æ˜“æ—¥æ•°æ®
            sw.rn > {history_trading_days}
            -- ğŸ“Œ æ¡ä»¶1ï¼šå½“æ—¥æ”¶ç›˜ä»·å¤§äºå‰Nä¸ªäº¤æ˜“æ—¥çš„æœ€é«˜æ”¶ç›˜ä»·çš„101%
            AND sw.adj_close_price > (sw.max_close_n_days * 1.01)
            -- ğŸ“Œ æ¡ä»¶2ï¼šå‰Nä¸ªäº¤æ˜“æ—¥å†…æœ‰æ¶¨å¹…ï¼ˆå¤§äºç­‰äº5%ï¼‰çš„Kçº¿
            {cond2_sql_where_clause}
            -- ğŸ“Œ æ¡ä»¶3ï¼šå‰Nä¸ªäº¤æ˜“æ—¥çš„è‚¡ç¥¨ä»·æ ¼æŒ¯å¹…åº¦ï¼Œä¸Šè¯å’Œæ·±è¯è‚¡ç¥¨å°äºç­‰äº25%(30%, 35%)ï¼Œåˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿è‚¡ç¥¨å°äºç­‰äº35%(40%, 40%)
            AND (
                -- âœ… æ ¹æ®è‚¡ç¥¨ä»£ç æ¿å—ï¼ˆå‰ç¼€ï¼‰ç¡®å®šæŒ¯å¹…é˜ˆå€¼
                CASE
                    WHEN sw.open_price_of_first_day_of_n_days > 0
                    THEN (sw.max_high_n_days - sw.min_low_n_days) * 1.0 / sw.open_price_of_first_day_of_n_days * 100
                    ELSE 999999 -- é¿å…é™¤é›¶é”™è¯¯
                END
            ) <= (
                CASE
                    -- âœ… åˆ›ä¸šæ¿ï¼ˆä»¥300ï¼Œ301ï¼Œ302å¼€å¤´ï¼‰æˆ–ç§‘åˆ›æ¿ï¼ˆä»¥688å¼€å¤´ï¼‰ï¼Œå°äºç­‰äº35%(40%, 40%)
                    WHEN sw.stock_code LIKE 'sz300%' OR sw.stock_code LIKE 'sz301%' OR sw.stock_code LIKE 'sz302%' OR sw.stock_code LIKE 'sh688%' THEN {non_main_board_amplitude_threshold}
                    -- âœ… ä¸Šè¯ä¸»æ¿ï¼ˆä»¥600ï¼Œ601ï¼Œ603ï¼Œ605å¼€å¤´ï¼‰å°äºç­‰äº25%(30%, 35%)
                    WHEN sw.stock_code LIKE 'sh600%' OR sw.stock_code LIKE 'sh601%' OR sw.stock_code LIKE 'sh603%' OR sw.stock_code LIKE 'sh605%' THEN {main_board_amplitude_threshold}
                    -- âœ… æ·±è¯ä¸»æ¿ï¼ˆä»¥000ï¼Œ001ï¼Œ002ï¼Œ003å¼€å¤´ï¼‰å°äºç­‰äº25%(30%, 35%)
                    WHEN sw.stock_code LIKE 'sz000%' OR sw.stock_code LIKE 'sz001%' OR sw.stock_code LIKE 'sz002%' OR sw.stock_code LIKE 'sz003%' THEN {main_board_amplitude_threshold}
                    ELSE 1000
                END
            )
            -- ğŸ“Œ æ¡ä»¶4ï¼šæµé€šå¸‚å€¼åœ¨30äº¿è‡³500äº¿ä¹‹é—´
            AND sw.market_cap_of_100_million BETWEEN {min_market_capitalization} AND {max_market_capitalization}
    ),
    LimitedRangeStockData AS (
        -- ğŸ”§ é™å®šèŒƒå›´ï¼šæ¯æ”¯è‚¡ç¥¨ä»å…¶ max_close_n_days_date èµ·ï¼Œå¾€åå– {days_limit} ä¸ªäº¤æ˜“æ—¥æ•°æ®
        SELECT *
        FROM StockWindows w
        WHERE EXISTS (
            SELECT 1
            FROM FilteredStockData f
            WHERE f.stock_code = w.stock_code
            AND w.trade_date BETWEEN f.max_close_n_days_date AND DATE_ADD(f.max_close_n_days_date, INTERVAL {days_limit} DAY)
        )
    )
    -- âœ… æœ€ç»ˆè¾“å‡º
    SELECT
        stock_code,
        stock_name,
        trade_date,
        max_close_n_days_date AS adj_support_date,
        ROUND(max_close_n_days, 2) AS adj_support_price,
        ROUND(adj_close_price, 2) AS adj_close_price,
        ROUND(adj_high_price, 2) AS adj_high_price,
        ROUND(adj_low_price, 2) AS adj_low_price,
        ROUND(adj_open_price, 2) AS adj_open_price,
        industry_level2,
        industry_level3
    FROM LimitedRangeStockData
    ORDER BY stock_code, trade_date;
    """
    
    # è·å–æŸ¥è¯¢ç»“æœ
    results_df = con.execute(query_sql).fetchdf()
    
    # å…³é—­è¿æ¥
    con.close()

    #è¿”å›æŸ¥è¯¢ç»“æœ
    return results_df

def find_support_and_dip_dates(
    limited_adjusted_df: pd.DataFrame, 
    targets: List[Dict[str, str]]
) -> pd.DataFrame:
    """
    æ ¹æ® DuckDB é¢„å¤„ç†çš„ limited_adjusted_dfï¼ŒæŸ¥æ‰¾å›è¸©æ—¥ã€‚
    
    ã€ä¿®æ”¹å†…å®¹ã€‘
    1. å¿½ç•¥çªç ´æ—¥åçš„ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºå›è¸©å¤‡é€‰ã€‚
    2. æ”¶é›†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å›è¸©æ—¥ã€‚
    """
    results = []
    
    # ç¡®ä¿ trade_date æ˜¯æ—¥æœŸç±»å‹
    limited_adjusted_df['trade_date'] = pd.to_datetime(limited_adjusted_df['trade_date'])

    for target in targets:
        stock_code = target['stock_code']
        breakthrough_date_str = target['breakthrough_date']
        stock_name = target['stock_name']
        
        try:
            breakthrough_date_dt = pd.to_datetime(breakthrough_date_str)
        except ValueError:
            print(f"Skipping {stock_code}: Invalid breakthrough_date format.")
            continue

        # 1. ç­›é€‰ç›®æ ‡è‚¡ç¥¨æ•°æ®
        stock_df = limited_adjusted_df[limited_adjusted_df['stock_code'] == stock_code].sort_values('trade_date').reset_index(drop=True)
        
        # 2. ç¡®å®šçªç ´æ—¥å’Œæ”¯æ’‘ä»·
        breakthrough_row = stock_df[stock_df['trade_date'] == breakthrough_date_dt]
        
        if breakthrough_row.empty:
            continue
        
        # è·å–æ”¯æ’‘ä»·å’Œæ”¯æ’‘æ—¥æœŸ
        support_price = breakthrough_row['adj_support_price'].iloc[0]
        support_date_dt = breakthrough_row['adj_support_date'].iloc[0] # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ adj_support_date
        
        if support_price is None or support_price == 0:
            continue

        # 3. ç¡®å®šå›è¸©çª—å£ (Dip Window)
        
        # çªç ´æ—¥ä½ç½®
        breakthrough_pos = stock_df.index.get_loc(breakthrough_row.index[0])
        
        # ã€ä¿®æ”¹ç‚¹ 1ï¼šå¿½ç•¥çªç ´æ—¥åçš„ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥ã€‘
        # å›è¸©çª—å£ä»çªç ´æ—¥åçš„ç¬¬äºŒä¸ªäº¤æ˜“æ—¥å¼€å§‹
        # dip_start_pos åŸä¸º breakthrough_pos + 1
        dip_start_pos = breakthrough_pos + 2 
        
        # æå–å›è¸©çª—å£çš„æ•°æ®ï¼šä»çªç ´æ—¥åç¬¬äºŒå¤©åˆ°æ•°æ®ç»“æŸ
        # ç¡®ä¿ dip_start_pos ä¸ä¼šè¶…å‡ºæ•°æ®èŒƒå›´
        if dip_start_pos >= len(stock_df):
             # æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ç»§ç»­æŸ¥æ‰¾å›è¸©ï¼Œè·³è¿‡å½“å‰è‚¡ç¥¨
             continue
             
        dip_window_df = stock_df.iloc[dip_start_pos:].copy()
        
        
        # 4. å¯»æ‰¾æ‰€æœ‰å›è¸©æ—¥ (Dip Dates)
        dip_dates = [] 
        
        if not dip_window_df.empty:
            # æ‰¾åˆ°æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å¤‡é€‰å›è¸©æ—¥ï¼ˆé€»è¾‘ä¸å˜ï¼‰
            # A. å¤‡é€‰å›è¸©æ—¥å½“å¤©çš„æœ€é«˜ä»·(adj_high_price)å’Œæœ€ä½ä»·(adj_low_price)*99.5%è¦åŒ…å«æ”¯æŒä»·
            condition_A = (dip_window_df['adj_high_price'] >= support_price) & \
                          (dip_window_df['adj_low_price'] * SUPPORT_PRICE_TOLERANCE <= support_price)
            
            # B. å¤‡é€‰å›è¸©æ—¥å½“å¤©çš„æ”¶ç›˜ä»·(adj_close_price)é«˜äºæ”¯æŒä»·(support_price)
            condition_B = dip_window_df['adj_close_price'] > support_price
            
            # C. å¤‡é€‰å›è¸©æ—¥å½“å¤©çš„æ³¢åŠ¨æ€§å°äº VOLATILITY_LIMIT
            # condition_C = (abs(dip_window_df['adj_close_price'] - dip_window_df['adj_open_price']) / dip_window_df['adj_open_price']) < VOLATILITY_LIMIT
            
            # candidate_dips = dip_window_df[condition_A & condition_B & condition_C]

            candidate_dips = dip_window_df[condition_A & condition_B]
            
            
            if not candidate_dips.empty:
                # ã€ä¿®æ”¹ç‚¹ 2ï¼šæ”¶é›†æ‰€æœ‰å›è¸©æ—¥ã€‘
                # å°†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„æ—¥æœŸè½¬æ¢ä¸º YYYY-MM-DD å­—ç¬¦ä¸²ï¼Œå¹¶æ”¶é›†åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­
                dip_dates = [dt.strftime('%Y-%m-%d') for dt in candidate_dips['trade_date'].tolist()]

        # 5. è®°å½•ç»“æœ
        # ã€ä¿®æ”¹ç‚¹ 2ï¼šå°†å¤šä¸ªå›è¸©æ—¥è¿æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²ã€‘
        # dip_date_str = ", ".join(dip_dates) if dip_dates else None
        
        # =============== ã€æ–°å¢è¿‡æ»¤é€»è¾‘ã€‘ ===============
        if not dip_dates:
            # å¦‚æœ dip_dates åˆ—è¡¨ä¸ºç©ºï¼Œåˆ™è·³è¿‡æœ¬æ¬¡å¾ªç¯ï¼Œä¸å°†ç»“æœæ·»åŠ åˆ° results
            continue
        # ===============================================

        for dip_date in dip_dates:
            results.append({
                'stock_code': stock_code,
                'stock_name': stock_name,
                # ç¡®ä¿çªç ´æ—¥å’Œæ”¯æ’‘æ—¥æ ¼å¼ç»Ÿä¸€ä¸º YYYY-MM-DD å­—ç¬¦ä¸²
                'breakthrough_date': breakthrough_date_dt.strftime('%Y-%m-%d'),
                'support_price': support_price,
                'support_date': support_date_dt.strftime('%Y-%m-%d'),
                'dip_date': dip_date
            })

    return pd.DataFrame(results)


if __name__ == '__main__':
    # è·å–æ•°æ®
    target_df = load_target_df("Table.xlsx")
    target_df['breakthrough_date'] = pd.to_datetime(target_df['breakthrough_date'])
    stock_data_list = target_df[['breakthrough_date', 'stock_code', 'stock_name']].to_dict('records')

    print("\næ‰§è¡Œç­›é€‰...")
    start_time = time.time()

    # 2. è®¡ç®—å‰å¤æƒæ•°æ®
    MAX_HOLDING_DAYS = 40
    limited_df = get_next_N_days_data(stock_data_list, MAX_HOLDING_DAYS)

    # 3. æŸ¥æ‰¾æ”¯æ’‘ä»·å’Œå›è¸©æ—¥
    final_results = find_support_and_dip_dates(limited_df, stock_data_list)
    
    # 4. è¾“å‡ºç»“æœ
    # print("\n--- æœ€ç»ˆç»“æœ ---")
    # print(final_results[['stock_code', 'stock_name', 'breakthrough_date', 'support_price', 'dip_date']].to_markdown(index=False))

    end_time = time.time()
    print(f"ç­›é€‰äº: {end_time - start_time:.2f}ç§’å†…å®Œæˆ.")

    # 5. å¯¼å‡ºåˆ° Excel æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    excel_file_name = f'å›è¸©ç­›é€‰ç»“æœ_{timestamp}.xlsx'
    
    # å¯¼å‡ºæ—¶ï¼Œåªä¿ç•™æ‚¨è¦æ±‚çš„å››åˆ—ï¼ˆåŠ ä¸Šæ”¯æ’‘ä»·æ–¹ä¾¿æ£€æŸ¥ï¼‰
    columns_to_export = [
        'stock_code', 
        'stock_name', 
        'breakthrough_date', 
        'dip_date',
        'support_date',
        'support_price' # å¯¼å‡ºæ”¯æ’‘ä»·æ–¹ä¾¿æŸ¥çœ‹
    ]
    
    # ä½¿ç”¨ to_excel æ–¹æ³•å¯¼å‡º
    final_results[columns_to_export].to_excel(
        excel_file_name, 
        index=False # ä¸å¯¼å‡º pandas çš„è¡Œç´¢å¼•
    )
    
    print(f"\nâœ… ç»“æœå·²æˆåŠŸå¯¼å‡ºåˆ°æ–‡ä»¶: {excel_file_name}")